# Story 2.7: Implement Archival Performance Metrics & ETC Calculation

## Status: Done

## Story

- As an Operator of the Archival System,
- I want the system to actively track its performance metrics (such as pages/threads archived per unit of time, and data volume downloaded) in real-time and use this data to provide dynamically updated Estimated Time to Completion (ETC) for the current archival task or batch, as well as to generate initial ETCs for future archival batches based on historical performance,
- So that I can effectively monitor the progress of potentially very long-running archival tasks, manage my expectations regarding timelines, and better plan the overall forum archival effort.

## Acceptance Criteria (ACs)

*These ACs are copied from `docs/epic-2.md` for Story 2.7.*

1.  **AC1:** The Archival System MUST continuously track its processing rate during operation. Key rates to track include:
    * Number of individual topic pages successfully downloaded and saved per unit of time (e.g., pages per minute).
    * Number of complete topics successfully archived per unit of time (e.g., topics per hour).
    * Volume of data downloaded per unit of time (e.g., MB per minute).
2.  **AC2:** While archiving a batch of topics (e.g., for a specific sub-forum, or the entire remaining list), the system MUST display and regularly update (e.g., every 5-10 minutes or after a significant number of items) an Estimated Time to Completion (ETC) for the *current* operational batch.
3.  **AC3:** The ETC for the current batch MUST be calculated based on the system's real-time measured processing rate(s) and the remaining number of known items (e.g., pages or topics) for that batch.
4.  **AC4:** The accuracy of the dynamically updated ETC for the current batch SHOULD improve as more of that batch is processed and the system "learns" its sustained rate for the current conditions.
5.  **AC5:** Upon completion of archiving a significant batch (e.g., all topics for a sub-forum, or the end of a scheduled operational window), the system MUST log summary performance metrics for that run. This includes total time taken, average processing rates (pages/minute, topics/hour, MB/minute), and total items/volume processed.
6.  **AC6:** This historical performance data (e.g., average processing rates from completed archival runs or batches) MUST be stored persistently in a simple local format (e.g., appended to a performance log file, or a small local database/structured text file).
7.  **AC7:** Before initiating the archival of a *new* batch of topics (e.g., the next sub-forum in the prioritized list), the system (or an associated utility function) MUST be able to provide an initial ETC for that batch. This estimate should be based on the known size of the new batch (e.g., total estimated number of pages derived from the Topic Index) and the stored historical average performance data.
8.  **AC8:** All displayed ETCs and logged processing rates MUST be presented in a clear, human-readable format (e.g., "ETC: ~3 days 4 hours 15 minutes", "Rate: 30 pages/min", "Processed: 1500 of 11000 topics").
9.  **AC9:** The collection and calculation of performance metrics and ETCs MUST NOT significantly degrade the primary performance or stability of the HTML download and storage tasks themselves.

## Tasks / Subtasks

- [X] Task 1: Define Metrics Data Structures & Storage (AC: 1, 6)
  - [X] Subtask 1.1: Design data structure for real-time tracking (rates, counts, start times).
  - [X] Subtask 1.2: Design format for persistent historical performance data (e.g., CSV, JSON lines).
  - [X] Subtask 1.3: Specify file path for historical data (e.g., `performance_log.csv` in logs directory).
- [X] Task 2: Implement Real-time Metrics Tracking (AC: 1, 9)
  - [X] Subtask 2.1: Develop logic to increment page/topic/byte counters upon successful archival.
  - [X] Subtask 2.2: Develop logic to calculate current rates (pages/min, topics/hr, MB/min).
  - [X] Subtask 2.3: Ensure metric collection is lightweight and efficient.
- [X] Task 3: Implement Current Batch ETC Calculation & Display (AC: 2, 3, 4, 8)
  - [X] Subtask 3.1: Develop logic to get remaining items (pages/topics) for the current batch.
  - [X] Subtask 3.2: Implement ETC formula using current rates and remaining items.
  - [X] Subtask 3.3: Implement periodic update mechanism for ETC display (e.g., via logger).
  - [X] Subtask 3.4: Format ETC and rates for human-readable output.
- [X] Task 4: Implement Historical Performance Logging (AC: 5, 6)
  - [X] Subtask 4.1: Develop logic to calculate summary metrics at the end of a batch/run.
  - [X] Subtask 4.2: Implement appending summary metrics to the persistent historical data file.
- [X] Task 5: Implement Initial ETC for New Batches (AC: 7, 8)
  - [X] Subtask 5.1: Develop logic to load/parse historical performance data.
  - [X] Subtask 5.2: Develop logic to estimate new batch size (e.g., from Topic Index).
  - [X] Subtask 5.3: Implement ETC formula for new batches using historical rates and new batch size.
  - [X] Subtask 5.4: Display initial ETC in a human-readable format.
- [ ] Task 6: Integration into Archival Script (Dependent on Story 2.8)
  - [ ] Subtask 6.1: Initialize metrics tracking at script start.
  - [ ] Subtask 6.2: Call update/display logic at appropriate points in the archival loop.
  - [ ] Subtask 6.3: Call historical logging at the end of batches/runs.
  - [ ] Subtask 6.4: Call initial ETC calculation before starting a new batch.
- [X] Task 7: Unit Testing
  - [X] Subtask 7.1: Test rate calculations (various inputs).
  - [X] Subtask 7.2: Test ETC calculations (current and initial).
  - [X] Subtask 7.3: Test historical data saving and loading.
  - [X] Subtask 7.4: Test human-readable formatting.

## Dev Technical Guidance

- **Time Tracking:** Use Go's `time` package for accurate duration measurements. `time.Now()` and `time.Since()` will be essential.
- **Data Structures:**
    - For real-time tracking, a struct holding start times, counters (pages, topics, bytes), and perhaps a small history of recent rates for smoothing.
    - For historical data, consider simple CSV or JSON lines for easy appending and parsing.
    ```csv
    // Example performance_log.csv
    TimestampUTC,BatchID,DurationSeconds,PagesArchived,TopicsArchived,BytesArchived,AvgPagesPerMin,AvgTopicsPerHour,AvgMBPerMin
    2025-05-27T10:00:00Z,subforum_X,3600,1800,30,512000000,30.0,30.0,8.14
    ```
- **ETC Calculation:**
    - Current Batch ETC: `RemainingItems / CurrentRate`. Ensure handling of zero rate (e.g., display "Calculating..." or "N/A").
    - Initial Batch ETC: `EstimatedNewBatchSize / AverageHistoricalRate`.
- **Human-Readable Format:** Create helper functions to format `time.Duration` into "X days Y hours Z minutes" and byte counts into MB/GB.
- **Configuration:** The path for the historical performance log file could be made configurable via `pkg/config/config.go` if desired, or default to a standard location (e.g., within a `logs` directory).
- **Logging vs. Display:** Distinguish between metrics logged to a file (persistent) and metrics displayed to the console (transient). AC2 implies console display for current ETC.

## Project Structure Notes
- Consider a new package `pkg/metrics` for all performance tracking, ETC calculation, and historical data logic.
- Modify `cmd/archiver/main.go` to integrate calls to `pkg/metrics`.
- If the historical log path is configurable, update `pkg/config/config.go`.

## Deviation Analysis
- No deviations anticipated from the epic definition.

## Testing Guidance
- Mock time-dependent functions (`time.Now`) for reproducible unit tests.
- Test with various scenarios:
    - Zero items processed (initial state).
    - Very fast processing rates.
    - Very slow processing rates.
    - No historical data available for initial ETC.
    - Large and small batch sizes.
- Ensure calculations handle potential division by zero gracefully.

## Story Progress Notes

### Agent Model Used: `Gemini 2.5 Pro (via Cursor)`

### Completion Notes List
- Created `pkg/metrics` package with core functionality:
  - `types.go`: Defines `BatchMetrics` and `HistoricalMetrics` structures
  - `persistence.go`: Implements CSV-based historical metrics storage
  - `formatting.go`: Provides human-readable formatting utilities
  - `metrics_test.go`: Comprehensive unit tests for all functionality
- Added `PerformanceLogPath` to `pkg/config/config.go`
- All core functionality is implemented and tested
- Task 6 (Integration into Archival Script) is deferred until Story 2.8
  - Will be implemented as part of Story 2.8's AC8: "The script accurately implements, tracks, and displays/logs the archival performance metrics and ETC calculations"
  - Integration points will be determined by the archival loop's structure
  - Will be tested as part of Story 2.9's AC8: "Metrics & ETC Validation"

### Change Log
- 2025-05-26: Implemented core metrics functionality and unit tests. Added performance log path to config.
- YYYY-MM-DD: Initial draft created by BMad IDE Orchestrator.

## Story Draft Checklist Report

This checklist is based on `